{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AVA-Gen \u00b6 AVA-Gen is an automated tool including two parts: A pipeline that converts existing Espresso UI tests (Java/Kotlin) into VA methods and using LLM calls (GPT APIs) to generate other code description artifacts. A runtime server and client architecture that support converting user request to the VA tasks. Demo video \u00b6 You can watch a short demo of AVA\u2011Gen in action here: https://youtu.be/z4p19QL6ejw Quick start \u00b6 Install the package from the project root: pip install . This installs the ava-gen CLI and the runtime components. Configure environment and OpenAI: Copy .env.example to .env , and edit it cp .env.example .env Set OPENAI_API_KEY and (optionally) variables such as AVA_GEN_OPENAI_MODEL Run your first end-to-end example using the real workspace/ folder and the bundled app hu.vmiklos.plees_tracker by following: docs/running_example.md This walks you through preparing inputs under workspace/ , running ava-gen pipeline hu.vmiklos.plees_tracker , and inspecting the generated artifacts (extracted tests, VA methods, skills, intents, action plans). Explore the CLI and pipelines for your own app (see docs/cli.md and docs/getting-started.md for details): ava-gen --help Start the runtime server (once workspace artifacts and action plans exist): uvicorn runtime.api.server:app --reload See the docs/ directory (used by MkDocs) for: docs/running_example.md \u2013 concrete running example on the real workspace. docs/cli.md \u2013 CLI usage and pipeline overview. docs/runtime_server_client.md \u2013 runtime usage.","title":"Home"},{"location":"#ava-gen","text":"AVA-Gen is an automated tool including two parts: A pipeline that converts existing Espresso UI tests (Java/Kotlin) into VA methods and using LLM calls (GPT APIs) to generate other code description artifacts. A runtime server and client architecture that support converting user request to the VA tasks.","title":"AVA-Gen"},{"location":"#demo-video","text":"You can watch a short demo of AVA\u2011Gen in action here: https://youtu.be/z4p19QL6ejw","title":"Demo video"},{"location":"#quick-start","text":"Install the package from the project root: pip install . This installs the ava-gen CLI and the runtime components. Configure environment and OpenAI: Copy .env.example to .env , and edit it cp .env.example .env Set OPENAI_API_KEY and (optionally) variables such as AVA_GEN_OPENAI_MODEL Run your first end-to-end example using the real workspace/ folder and the bundled app hu.vmiklos.plees_tracker by following: docs/running_example.md This walks you through preparing inputs under workspace/ , running ava-gen pipeline hu.vmiklos.plees_tracker , and inspecting the generated artifacts (extracted tests, VA methods, skills, intents, action plans). Explore the CLI and pipelines for your own app (see docs/cli.md and docs/getting-started.md for details): ava-gen --help Start the runtime server (once workspace artifacts and action plans exist): uvicorn runtime.api.server:app --reload See the docs/ directory (used by MkDocs) for: docs/running_example.md \u2013 concrete running example on the real workspace. docs/cli.md \u2013 CLI usage and pipeline overview. docs/runtime_server_client.md \u2013 runtime usage.","title":"Quick start"},{"location":"cli/","text":"AVA-Gen CLI Guide \u00b6 This document describes the AVA-Gen command-line interface (CLI) and how it orchestrates the end-to-end workflow from raw test classes to runtime-ready artifacts for the AVA-Gen server. The CLI lives in cli/main.py and is exposed as the ava-gen command when you install the package. Installation \u00b6 From the project root: pip install . # or pipx install . Once installed: ava-gen --help Configuration \u00b6 AVA-Gen reads configuration from environment variables (optionally via a .env file). Copy .env.example to .env and fill in your values: OPENAI_API_KEY (required) \u2013 your OpenAI key. OPENAI_BASE_URL (optional) \u2013 custom API base URL or proxy. AVA_GEN_OPENAI_MODEL (optional) \u2013 default model (default: gpt-4.1-mini ). AVA_GEN_INTENT_MODEL (optional) \u2013 model for intent matching (defaults to AVA_GEN_OPENAI_MODEL ). AVA_GEN_WORKSPACE_ROOT (optional) \u2013 workspace root (default: workspace ). AVA_GEN_RUNTIME_DATA_DIR (optional) \u2013 runtime data dir (default: runtime/data ). The CLI option --workspace-root always takes precedence over AVA_GEN_WORKSPACE_ROOT . Overview \u00b6 High-level pipeline (per app): Step Command Purpose Key outputs 1 ava-gen prepare <app_id> ... Copy raw test classes / app intro into the workspace. workspace/<app_id>/input/ 2 ava-gen extract <app_id> Parse Espresso tests into per-test Java methods. workspace/<app_id>/extracted_tests/ 3 ava-gen generate-va <app_id> Convert extracted tests into VA methods. workspace/<app_id>/va_methods/ 4 ava-gen build-skills <app_id> Build skill/context descriptions from VA methods. workspace/skills_description/<app_id>_skills_description.json 5 ava-gen build-intents Aggregate intents and intent\u2192method mapping (all apps). workspace/intent/intent_list_full.json , workspace/intent/intent_method_map.json 6 ava-gen actionplan <app_id> Build ActionPlans from VA methods for the given app. workspace/actionplan/<app_id>_actionplan.json 7 ava-gen pipeline <app_id> Convenience command that runs steps 2\u20136 for one app. All of the above for <app_id> The VA runtime server is started separately, for example: uvicorn runtime.api.server:app --reload All commands accept an optional --workspace-root argument (default: workspace ). Global options \u00b6 ava-gen <command> [options] ava-gen --workspace-root <PATH> <command> [options] By default, the workspace root is taken from AVA_GEN_WORKSPACE_ROOT or ./workspace if the env var is not set. --workspace-root PATH Overrides the workspace root for a single command. Important --workspace-root is a global option. It must appear before the subcommand name ( prepare , extract , pipeline , etc.), not after the app_id . 1. prepare \u2013 copy files into workspace input \u00b6 Prepare the workspace for a specific app by copying a single file into the app's input/ folder. You can call this multiple times (for test classes and an optional app introduction text). Usage \u00b6 ava-gen prepare <app_id> path/to/file Behavior \u00b6 Creates (if needed): workspace/<app_id>/input/ Copies: path/to/file \u2192 workspace/<app_id>/input/<original_name> Call this once for your test class, e.g.: ava-gen prepare com.example.myapp path/to/MyAppTest.java And optionally once for your app introduction: ava-gen prepare com.example.myapp path/to/app_introduction.txt Example output \u00b6 [AVA-Gen] Preparing workspace for app_id=hu.vmiklos.plees_tracker [AVA-Gen] \u2795 Copying file: tests/PleesTrackerTests.java \u2192 workspace/hu.vmiklos.plees_tracker/input/PleesTrackerTests.java [AVA-Gen] Workspace input updated 2. extract \u2013 extract test methods \u00b6 Run the Espresso test parser and populate extracted_tests/ for the app. Usage \u00b6 ava-gen extract <app_id> Behavior \u00b6 Calls process_app_workspace(app_id, workspace_root) (converter pipeline). Reports how many test methods were extracted. Uses: workspace/<app_id>/extracted_tests/ Example output \u00b6 [AVA-Gen] Parsing test scripts for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 12 test methods extracted \u2192 workspace/hu.vmiklos.plees_tracker/extracted_tests/ Note Internally, process_app_workspace also populates va_methods/ , but this command focuses on reporting the extracted tests. 3. generate-va \u2013 generate VA methods \u00b6 Generate VA methods from the extracted tests for a specific app. Usage \u00b6 ava-gen generate-va <app_id> Behavior \u00b6 Reuses process_app_workspace(app_id, workspace_root) to ensure that extracted_tests/ and va_methods/ are in sync. Counts the generated VA method files. Uses: workspace/<app_id>/va_methods/ Example output \u00b6 [AVA-Gen] Generating VA methods for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 5 VA methods created \u2192 workspace/hu.vmiklos.plees_tracker/va_methods/ 4. build-skills \u2013 build skills_description JSON \u00b6 Build skill/context descriptions for a specific app using the skill interpreter. Usage \u00b6 ava-gen build-skills <app_id> Behavior \u00b6 Calls core.interpreter.skill_interpreter.interpret(workspace_root, app_id) . Writes a skills/contexts JSON file to: workspace/skills_description/<app_id>_skills_description.json Example output \u00b6 [AVA-Gen] Building JSON skill descriptions for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json written 5. build-intents \u2013 build global intent artifacts \u00b6 Build the global intent list and intent\u2192method map used by the runtime intent validator. Usage \u00b6 ava-gen build-intents Behavior \u00b6 Uses core.interpreter.intent_interpreter.IntentInterpreter . Aggregates all *_skills_description.json files. Writes: workspace/intent/intent_list_full.json \u2013 per-app intent strings (and optional intent_summary sentence) for GPT intent matching and capability summaries. workspace/intent/intent_method_map.json \u2013 per-app intent \u2192 method_name mapping. Example output \u00b6 [AVA-Gen] Building global intent list and intent\u2192method map... [AVA-Gen] \u2713 workspace/intent/intent_list_full.json written [AVA-Gen] \u2713 workspace/intent/intent_method_map.json written 6. actionplan \u2013 build ActionPlans for one app \u00b6 Build ActionPlans for a specific app based on its generated VA methods. Usage \u00b6 ava-gen actionplan <app_id> Behavior \u00b6 Uses core.actionplan.actionplan_parser.generate_action_plans_for_app . Reads: workspace/<app_id>/va_methods/*.java Writes: workspace/actionplan/<app_id>_actionplan.json Example output \u00b6 [AVA-Gen] Building ActionPlans for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] Action plans written to: workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json 7. pipeline \u2013 run the full chain for one app \u00b6 Run the main pipeline steps (2\u20136) for a single app in one command. Usage \u00b6 ava-gen pipeline <app_id> [--skip-intents] --skip-intents If provided, skips the build-intents step and only generates app-specific artifacts (extracted tests, VA methods, skills_description). Behavior \u00b6 For the given app_id , runs: extract (via process_app_workspace ) generate-va (counting VA method files) build-skills build-intents (unless --skip-intents is set) actionplan Example output \u00b6 [AVA-Gen] Running full pipeline for app_id=hu.vmiklos.plees_tracker [AVA-Gen] Parsing test scripts... [AVA-Gen] 12 test methods extracted [AVA-Gen] Generating VA methods... [AVA-Gen] 5 VA methods created [AVA-Gen] Building JSON skill descriptions... [AVA-Gen] workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json written [AVA-Gen] Building global intent artifacts... [AVA-Gen] workspace/intent/intent_list_full.json written [AVA-Gen] workspace/intent/intent_method_map.json written [AVA-Gen] Building ActionPlans... [AVA-Gen] Action plans written to: workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json [AVA-Gen] All artifacts ready for runtime [AVA-Gen] Next step: start the VA runtime server [AVA-Gen] uvicorn runtime.api.server:app --reload If --skip-intents is used: [AVA-Gen] Building global intent artifacts... (skipped) 7. Starting the runtime server \u00b6 After running the CLI pipeline (either via individual commands or pipeline ), the VA-Gen runtime server can be started separately: uvicorn runtime.api.server:app --reload The server will then use: workspace/skills_description/ for skills/contexts workspace/intent/intent_list_full.json and intent_method_map.json for intent validation workspace/actionplan/<app_id>_actionplan.json for ActionPlans You can interact with the server using tools like Postman or your Android client.","title":"CLI Guide"},{"location":"cli/#ava-gen-cli-guide","text":"This document describes the AVA-Gen command-line interface (CLI) and how it orchestrates the end-to-end workflow from raw test classes to runtime-ready artifacts for the AVA-Gen server. The CLI lives in cli/main.py and is exposed as the ava-gen command when you install the package.","title":"AVA-Gen CLI Guide"},{"location":"cli/#installation","text":"From the project root: pip install . # or pipx install . Once installed: ava-gen --help","title":"Installation"},{"location":"cli/#configuration","text":"AVA-Gen reads configuration from environment variables (optionally via a .env file). Copy .env.example to .env and fill in your values: OPENAI_API_KEY (required) \u2013 your OpenAI key. OPENAI_BASE_URL (optional) \u2013 custom API base URL or proxy. AVA_GEN_OPENAI_MODEL (optional) \u2013 default model (default: gpt-4.1-mini ). AVA_GEN_INTENT_MODEL (optional) \u2013 model for intent matching (defaults to AVA_GEN_OPENAI_MODEL ). AVA_GEN_WORKSPACE_ROOT (optional) \u2013 workspace root (default: workspace ). AVA_GEN_RUNTIME_DATA_DIR (optional) \u2013 runtime data dir (default: runtime/data ). The CLI option --workspace-root always takes precedence over AVA_GEN_WORKSPACE_ROOT .","title":"Configuration"},{"location":"cli/#overview","text":"High-level pipeline (per app): Step Command Purpose Key outputs 1 ava-gen prepare <app_id> ... Copy raw test classes / app intro into the workspace. workspace/<app_id>/input/ 2 ava-gen extract <app_id> Parse Espresso tests into per-test Java methods. workspace/<app_id>/extracted_tests/ 3 ava-gen generate-va <app_id> Convert extracted tests into VA methods. workspace/<app_id>/va_methods/ 4 ava-gen build-skills <app_id> Build skill/context descriptions from VA methods. workspace/skills_description/<app_id>_skills_description.json 5 ava-gen build-intents Aggregate intents and intent\u2192method mapping (all apps). workspace/intent/intent_list_full.json , workspace/intent/intent_method_map.json 6 ava-gen actionplan <app_id> Build ActionPlans from VA methods for the given app. workspace/actionplan/<app_id>_actionplan.json 7 ava-gen pipeline <app_id> Convenience command that runs steps 2\u20136 for one app. All of the above for <app_id> The VA runtime server is started separately, for example: uvicorn runtime.api.server:app --reload All commands accept an optional --workspace-root argument (default: workspace ).","title":"Overview"},{"location":"cli/#global-options","text":"ava-gen <command> [options] ava-gen --workspace-root <PATH> <command> [options] By default, the workspace root is taken from AVA_GEN_WORKSPACE_ROOT or ./workspace if the env var is not set. --workspace-root PATH Overrides the workspace root for a single command. Important --workspace-root is a global option. It must appear before the subcommand name ( prepare , extract , pipeline , etc.), not after the app_id .","title":"Global options"},{"location":"cli/#1-prepare-copy-files-into-workspace-input","text":"Prepare the workspace for a specific app by copying a single file into the app's input/ folder. You can call this multiple times (for test classes and an optional app introduction text).","title":"1. prepare \u2013 copy files into workspace input"},{"location":"cli/#usage","text":"ava-gen prepare <app_id> path/to/file","title":"Usage"},{"location":"cli/#behavior","text":"Creates (if needed): workspace/<app_id>/input/ Copies: path/to/file \u2192 workspace/<app_id>/input/<original_name> Call this once for your test class, e.g.: ava-gen prepare com.example.myapp path/to/MyAppTest.java And optionally once for your app introduction: ava-gen prepare com.example.myapp path/to/app_introduction.txt","title":"Behavior"},{"location":"cli/#example-output","text":"[AVA-Gen] Preparing workspace for app_id=hu.vmiklos.plees_tracker [AVA-Gen] \u2795 Copying file: tests/PleesTrackerTests.java \u2192 workspace/hu.vmiklos.plees_tracker/input/PleesTrackerTests.java [AVA-Gen] Workspace input updated","title":"Example output"},{"location":"cli/#2-extract-extract-test-methods","text":"Run the Espresso test parser and populate extracted_tests/ for the app.","title":"2. extract \u2013 extract test methods"},{"location":"cli/#usage_1","text":"ava-gen extract <app_id>","title":"Usage"},{"location":"cli/#behavior_1","text":"Calls process_app_workspace(app_id, workspace_root) (converter pipeline). Reports how many test methods were extracted. Uses: workspace/<app_id>/extracted_tests/","title":"Behavior"},{"location":"cli/#example-output_1","text":"[AVA-Gen] Parsing test scripts for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 12 test methods extracted \u2192 workspace/hu.vmiklos.plees_tracker/extracted_tests/ Note Internally, process_app_workspace also populates va_methods/ , but this command focuses on reporting the extracted tests.","title":"Example output"},{"location":"cli/#3-generate-va-generate-va-methods","text":"Generate VA methods from the extracted tests for a specific app.","title":"3. generate-va \u2013 generate VA methods"},{"location":"cli/#usage_2","text":"ava-gen generate-va <app_id>","title":"Usage"},{"location":"cli/#behavior_2","text":"Reuses process_app_workspace(app_id, workspace_root) to ensure that extracted_tests/ and va_methods/ are in sync. Counts the generated VA method files. Uses: workspace/<app_id>/va_methods/","title":"Behavior"},{"location":"cli/#example-output_2","text":"[AVA-Gen] Generating VA methods for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 5 VA methods created \u2192 workspace/hu.vmiklos.plees_tracker/va_methods/","title":"Example output"},{"location":"cli/#4-build-skills-build-skills_description-json","text":"Build skill/context descriptions for a specific app using the skill interpreter.","title":"4. build-skills \u2013 build skills_description JSON"},{"location":"cli/#usage_3","text":"ava-gen build-skills <app_id>","title":"Usage"},{"location":"cli/#behavior_3","text":"Calls core.interpreter.skill_interpreter.interpret(workspace_root, app_id) . Writes a skills/contexts JSON file to: workspace/skills_description/<app_id>_skills_description.json","title":"Behavior"},{"location":"cli/#example-output_3","text":"[AVA-Gen] Building JSON skill descriptions for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] \u2713 workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json written","title":"Example output"},{"location":"cli/#5-build-intents-build-global-intent-artifacts","text":"Build the global intent list and intent\u2192method map used by the runtime intent validator.","title":"5. build-intents \u2013 build global intent artifacts"},{"location":"cli/#usage_4","text":"ava-gen build-intents","title":"Usage"},{"location":"cli/#behavior_4","text":"Uses core.interpreter.intent_interpreter.IntentInterpreter . Aggregates all *_skills_description.json files. Writes: workspace/intent/intent_list_full.json \u2013 per-app intent strings (and optional intent_summary sentence) for GPT intent matching and capability summaries. workspace/intent/intent_method_map.json \u2013 per-app intent \u2192 method_name mapping.","title":"Behavior"},{"location":"cli/#example-output_4","text":"[AVA-Gen] Building global intent list and intent\u2192method map... [AVA-Gen] \u2713 workspace/intent/intent_list_full.json written [AVA-Gen] \u2713 workspace/intent/intent_method_map.json written","title":"Example output"},{"location":"cli/#6-actionplan-build-actionplans-for-one-app","text":"Build ActionPlans for a specific app based on its generated VA methods.","title":"6. actionplan \u2013 build ActionPlans for one app"},{"location":"cli/#usage_5","text":"ava-gen actionplan <app_id>","title":"Usage"},{"location":"cli/#behavior_5","text":"Uses core.actionplan.actionplan_parser.generate_action_plans_for_app . Reads: workspace/<app_id>/va_methods/*.java Writes: workspace/actionplan/<app_id>_actionplan.json","title":"Behavior"},{"location":"cli/#example-output_5","text":"[AVA-Gen] Building ActionPlans for app_id=hu.vmiklos.plees_tracker... [AVA-Gen] Action plans written to: workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json","title":"Example output"},{"location":"cli/#7-pipeline-run-the-full-chain-for-one-app","text":"Run the main pipeline steps (2\u20136) for a single app in one command.","title":"7. pipeline \u2013 run the full chain for one app"},{"location":"cli/#usage_6","text":"ava-gen pipeline <app_id> [--skip-intents] --skip-intents If provided, skips the build-intents step and only generates app-specific artifacts (extracted tests, VA methods, skills_description).","title":"Usage"},{"location":"cli/#behavior_6","text":"For the given app_id , runs: extract (via process_app_workspace ) generate-va (counting VA method files) build-skills build-intents (unless --skip-intents is set) actionplan","title":"Behavior"},{"location":"cli/#example-output_6","text":"[AVA-Gen] Running full pipeline for app_id=hu.vmiklos.plees_tracker [AVA-Gen] Parsing test scripts... [AVA-Gen] 12 test methods extracted [AVA-Gen] Generating VA methods... [AVA-Gen] 5 VA methods created [AVA-Gen] Building JSON skill descriptions... [AVA-Gen] workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json written [AVA-Gen] Building global intent artifacts... [AVA-Gen] workspace/intent/intent_list_full.json written [AVA-Gen] workspace/intent/intent_method_map.json written [AVA-Gen] Building ActionPlans... [AVA-Gen] Action plans written to: workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json [AVA-Gen] All artifacts ready for runtime [AVA-Gen] Next step: start the VA runtime server [AVA-Gen] uvicorn runtime.api.server:app --reload If --skip-intents is used: [AVA-Gen] Building global intent artifacts... (skipped)","title":"Example output"},{"location":"cli/#7-starting-the-runtime-server","text":"After running the CLI pipeline (either via individual commands or pipeline ), the VA-Gen runtime server can be started separately: uvicorn runtime.api.server:app --reload The server will then use: workspace/skills_description/ for skills/contexts workspace/intent/intent_list_full.json and intent_method_map.json for intent validation workspace/actionplan/<app_id>_actionplan.json for ActionPlans You can interact with the server using tools like Postman or your Android client.","title":"7. Starting the runtime server"},{"location":"running_example/","text":"AVA-Gen Running Example for preparing VA-Ready Artifacts \u00b6 This guide walks through a concrete, end-to-end example that generating all the VA-Ready Artifacts that your AVA-Gen sever may need later, using the example tests and application descriptions under workspace/ folder and the bundled example app: app_id : hu.vmiklos.plees_tracker We assume you have already: Installed AVA\u2011Gen from this repo ( pip install . or pipx install ava-gen ) Configured OPENAI_API_KEY via environment or .env All commands below are run from the project root (where pyproject.toml lives). 1. Prepare the example in the real workspace \u00b6 This repo ships an example test and app introduction under: examples/hu.vmiklos.plees_tracker/DeleteAllSleepsTest.java examples/hu.vmiklos.plees_tracker/app_introduction.txt Use the prepare command to copy these into the workspace/ folder: ava-gen prepare hu.vmiklos.plees_tracker examples/hu.vmiklos.plees_tracker/DeleteAllSleepsTest.java ava-gen prepare hu.vmiklos.plees_tracker examples/hu.vmiklos.plees_tracker/app_introduction.txt After this, your real workspace will contain: workspace/ hu.vmiklos.plees_tracker/ input/ DeleteAllSleepsTest.java app_introduction.txt This is exactly the same structure you will use for your own apps, just with a different {app_id} , different tests and app introduction. 2. Run the pipeline for hu.vmiklos.plees_tracker \u00b6 Now run the full pipeline against the workspace/ : ava-gen pipeline hu.vmiklos.plees_tracker This will automatically: Parse the Espresso test class from workspace/hu.vmiklos.plees_tracker/input/ Generate Code Artifacts : workspace/hu.vmiklos.plees_tracker/extracted_tests/ \u2013 per-test method Java files workspace/hu.vmiklos.plees_tracker/va_methods/ \u2013 converted VA methods Generate Description Artifacts : workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json After the command completes, your workspace will look roughly like: workspace/ actionplan/ hu.vmiklos.plees_tracker_actionplan.json intent/ intent_list_full.json intent_method_map.json skills_description/ hu.vmiklos.plees_tracker_skills_description.json hu.vmiklos.plees_tracker/ input/ DeleteAllSleepsTest.java app_introduction.txt extracted_tests/ deleteAllSleepsTest.java va_methods/ deleteAllSleeps.java Congratulations! Now you have succesfully generate all the VA-Ready Artifcats for your app hu.vmiklos.plees_tracker with skill extracted from test method DeleteAllSleepsTest.java The AVA-Gen server is ready to use all these artifacts to support the Voice Assistant on deleting all sleeps. Please see this to check details about AVA-Gen runtime server-client architecture. 3. Adapt the pattern to your own app \u00b6 To use AVA\u2011Gen with your own app under the same workspace/ root: Choose your app id, e.g. com.example.myapp . Prepare input files: ava-gen prepare com.example.myapp path/to/MyAppTest.java ava-gen prepare com.example.myapp path/to/app_introduction.txt # optional Run the pipeline: ava-gen pipeline com.example.myapp You will get the same kinds of outputs as the hu.vmiklos.plees_tracker example, but under workspace/com.example.myapp/ and shared workspace/skills_description , workspace/intent , and workspace/actionplan . 4. (Optional) Start the runtime server \u00b6 Once your example (and/or your own app) has been processed via the pipeline, you can start the runtime server from the project root: uvicorn runtime.api.server:app --reload Before starting the server, make sure: workspace/hu.vmiklos.plees_tracker/actionplan/hu.vmiklos.plees_tracker_actionplan.json exists (and similarly for your own {app_id} ) workspace/intent/intent_list_full.json and workspace/intent/intent_method_map.json have been generated Your tools or clients can then talk to the server at: http://127.0.0.1:8000/agent using the ActionPlans and skills that were generated in the real workspace/ folder.","title":"Running Example"},{"location":"running_example/#ava-gen-running-example-for-preparing-va-ready-artifacts","text":"This guide walks through a concrete, end-to-end example that generating all the VA-Ready Artifacts that your AVA-Gen sever may need later, using the example tests and application descriptions under workspace/ folder and the bundled example app: app_id : hu.vmiklos.plees_tracker We assume you have already: Installed AVA\u2011Gen from this repo ( pip install . or pipx install ava-gen ) Configured OPENAI_API_KEY via environment or .env All commands below are run from the project root (where pyproject.toml lives).","title":"AVA-Gen Running Example for preparing VA-Ready Artifacts"},{"location":"running_example/#1-prepare-the-example-in-the-real-workspace","text":"This repo ships an example test and app introduction under: examples/hu.vmiklos.plees_tracker/DeleteAllSleepsTest.java examples/hu.vmiklos.plees_tracker/app_introduction.txt Use the prepare command to copy these into the workspace/ folder: ava-gen prepare hu.vmiklos.plees_tracker examples/hu.vmiklos.plees_tracker/DeleteAllSleepsTest.java ava-gen prepare hu.vmiklos.plees_tracker examples/hu.vmiklos.plees_tracker/app_introduction.txt After this, your real workspace will contain: workspace/ hu.vmiklos.plees_tracker/ input/ DeleteAllSleepsTest.java app_introduction.txt This is exactly the same structure you will use for your own apps, just with a different {app_id} , different tests and app introduction.","title":"1. Prepare the example in the real workspace"},{"location":"running_example/#2-run-the-pipeline-for-huvmiklosplees_tracker","text":"Now run the full pipeline against the workspace/ : ava-gen pipeline hu.vmiklos.plees_tracker This will automatically: Parse the Espresso test class from workspace/hu.vmiklos.plees_tracker/input/ Generate Code Artifacts : workspace/hu.vmiklos.plees_tracker/extracted_tests/ \u2013 per-test method Java files workspace/hu.vmiklos.plees_tracker/va_methods/ \u2013 converted VA methods Generate Description Artifacts : workspace/skills_description/hu.vmiklos.plees_tracker_skills_description.json workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json workspace/actionplan/hu.vmiklos.plees_tracker_actionplan.json After the command completes, your workspace will look roughly like: workspace/ actionplan/ hu.vmiklos.plees_tracker_actionplan.json intent/ intent_list_full.json intent_method_map.json skills_description/ hu.vmiklos.plees_tracker_skills_description.json hu.vmiklos.plees_tracker/ input/ DeleteAllSleepsTest.java app_introduction.txt extracted_tests/ deleteAllSleepsTest.java va_methods/ deleteAllSleeps.java Congratulations! Now you have succesfully generate all the VA-Ready Artifcats for your app hu.vmiklos.plees_tracker with skill extracted from test method DeleteAllSleepsTest.java The AVA-Gen server is ready to use all these artifacts to support the Voice Assistant on deleting all sleeps. Please see this to check details about AVA-Gen runtime server-client architecture.","title":"2. Run the pipeline for hu.vmiklos.plees_tracker"},{"location":"running_example/#3-adapt-the-pattern-to-your-own-app","text":"To use AVA\u2011Gen with your own app under the same workspace/ root: Choose your app id, e.g. com.example.myapp . Prepare input files: ava-gen prepare com.example.myapp path/to/MyAppTest.java ava-gen prepare com.example.myapp path/to/app_introduction.txt # optional Run the pipeline: ava-gen pipeline com.example.myapp You will get the same kinds of outputs as the hu.vmiklos.plees_tracker example, but under workspace/com.example.myapp/ and shared workspace/skills_description , workspace/intent , and workspace/actionplan .","title":"3. Adapt the pattern to your own app"},{"location":"running_example/#4-optional-start-the-runtime-server","text":"Once your example (and/or your own app) has been processed via the pipeline, you can start the runtime server from the project root: uvicorn runtime.api.server:app --reload Before starting the server, make sure: workspace/hu.vmiklos.plees_tracker/actionplan/hu.vmiklos.plees_tracker_actionplan.json exists (and similarly for your own {app_id} ) workspace/intent/intent_list_full.json and workspace/intent/intent_method_map.json have been generated Your tools or clients can then talk to the server at: http://127.0.0.1:8000/agent using the ActionPlans and skills that were generated in the real workspace/ folder.","title":"4. (Optional) Start the runtime server"},{"location":"runtime_server_client/","text":"Using the AVA\u2011Gen Runtime (Server & Client) \u00b6 This guide explains how to: Start the AVA\u2011Gen runtime server. Call the /agent HTTP endpoints from a client. Connect an Android emulator or a real phone to the server. Note the small differences for macOS vs. Windows hosts. It assumes you have already: Installed AVA\u2011Gen ( pip install . or pipx install ava-gen ). Configured OPENAI_API_KEY and run the pipeline so that: workspace/skills_description/*.json workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json workspace/actionplan/<app_id>_actionplan.json exist for at least one app (e.g. hu.vmiklos.plees_tracker ). 1. Start the runtime server \u00b6 From the project root: uvicorn runtime.api.server:app --reload This will: Load configuration from your environment / .env (see configs/settings.py ). Initialize the intent validator, action plan store, and session store. Expose the FastAPI app on http://127.0.0.1:8000 by default. If the uvicorn command is not found, use the Python module form instead: macOS / Linux python -m uvicorn runtime.api.server:app --reload Windows (PowerShell / Command Prompt) py -m uvicorn runtime.api.server:app --reload Tip: To allow access from other devices on your local network, bind to all interfaces: uvicorn runtime.api.server:app --host 0.0.0.0 --port 8000 --reload You can verify the server is up by opening: http://127.0.0.1:8000/agent/healthz You should see: { \"status\": \"ok\" } 2. Using an Android emulator \u00b6 To run the example app (or your own APK) in an Android emulator and connect it to the AVA\u2011Gen runtime server, you will typically: Start the emulator. Install the AVA\u2011Gen client APK ( ava-gen-client.apk ). Install your example/app-under-test APK. Configure the client app to talk to the host machine ( 10.0.2.2:8000 ). 2.1 Start an emulator \u00b6 Use Android Studio\u2019s AVD Manager or the command line: Open Android Studio \u2192 Device Manager \u2192 create / start a virtual device. Or run: emulator -avd <your_avd_name> 2.2 Install the AVA\u2011Gen client APK \u00b6 Once the emulator is running, install the provided AVA\u2011Gen client APK: adb install client/ava-gen-client_v1.apk On first launch, make sure: The app has Microphone permission (Search Permissions \u2192 Microphone and enable it). If your test device/emulator groups these permissions under Accessibility, ensure the microphone permission is enabled there as well. 2.3 Install your example/app-under-test APK \u00b6 Once the emulator is running, install your example APK via adb : adb install path/to/your_app.apk If you rebuilt the APK, you may need: adb install -r path/to/your_app.apk For the running example of hu.vmiklos.plees_tracker , please: adb install examples/plees-tracker-24.8.1.apk You should see AVA-Gen app in the Accessibility Tool List after the installation. 2.4 Configure the client app to talk to the server \u00b6 Inside an Android emulator: 10.0.2.2 is a special alias that points to your host\u2019s 127.0.0.1 . So as long as you run the server and the emulator (with client) on the same computer (MacOS or Windows), you should see everything connect together automatically. 3. Using a real Android device (phone) \u00b6 You can also connect a physical phone to the AVA\u2011Gen runtime running on your Mac or Windows machine. There are two common patterns: Use adb reverse (USB cable, no Wi\u2011Fi configuration). Put both phone and host on the same Wi\u2011Fi network (Not tested) 3.1 Using adb reverse (recommended for development) \u00b6 This works on Android 5.0+ and does not require exposing your server on the LAN. Enable USB debugging on your phone (Developer options). Connect the phone via USB. Verify the device is recognized: adb devices Start the AVA\u2011Gen server on your host: uvicorn runtime.api.server:app --reload Run adb reverse so the device can reach the host\u2019s port 8000 via its own localhost : adb reverse tcp:8000 tcp:8000 When the app calls, traffic is forwarded over USB to the AVA\u2011Gen server running on your Mac or Windows machine. On some cases, firewalls can block incoming connections. If the app cannot reach the server, check your firewall settings on macOS (System Settings \u2192 Network/Firewall) or Windows (Windows Defender Firewall). 4. Test the HTTP API from your desktop (curl / Postman) \u00b6 Once the server is running, you can exercise the /agent API directly from your Mac or Windows machine. This is useful for debugging before wiring up the Android client. The runtime exposes three key endpoints, all under the /agent prefix: GET /agent/healthz Simple health check. POST /agent/start_session Returns a new session_id you use for subsequent requests. POST /agent/request Main interaction endpoint; takes user messages plus session_id and app_id , and returns an AgentResponse (clarifying questions or an ActionPlan). 4.1 Start a session (curl) \u00b6 curl -X POST http://127.0.0.1:8000/agent/start_session Example response: { \"session_id\": \"abc123-session-id\" } 4.2 Send a request (curl) \u00b6 Use the session_id above and the app id you have processed (for example hu.vmiklos.plees_tracker ): curl -X POST http://127.0.0.1:8000/agent/request \\ -H \"Content-Type: application/json\" \\ -d '{ \"session_id\": \"abc123-session-id\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"message\": \"Delete all existing sleep records\" }' The response shape is defined in runtime/models/api_models.py and normally includes a high-level status and, when applicable, an ActionPlan derived from your workspace/actionplan/<app_id>_actionplan.json . 4.3 Use Postman (or similar) \u00b6 If you prefer a GUI client like Postman or Insomnia: Create a new POST request to http://127.0.0.1:8000/agent/start_session . Send the request and copy the session_id from the JSON response. Create another POST request to http://127.0.0.1:8000/agent/request . Set the body type to raw JSON and provide: { \"session_id\": \"abc123-session-id\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"message\": \"Delete all existing sleep records\" } Send the request and inspect the JSON response (clarifications, selected ActionPlan, etc.).","title":"Runtime Server & Client"},{"location":"runtime_server_client/#using-the-avagen-runtime-server-client","text":"This guide explains how to: Start the AVA\u2011Gen runtime server. Call the /agent HTTP endpoints from a client. Connect an Android emulator or a real phone to the server. Note the small differences for macOS vs. Windows hosts. It assumes you have already: Installed AVA\u2011Gen ( pip install . or pipx install ava-gen ). Configured OPENAI_API_KEY and run the pipeline so that: workspace/skills_description/*.json workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json workspace/actionplan/<app_id>_actionplan.json exist for at least one app (e.g. hu.vmiklos.plees_tracker ).","title":"Using the AVA\u2011Gen Runtime (Server &amp; Client)"},{"location":"runtime_server_client/#1-start-the-runtime-server","text":"From the project root: uvicorn runtime.api.server:app --reload This will: Load configuration from your environment / .env (see configs/settings.py ). Initialize the intent validator, action plan store, and session store. Expose the FastAPI app on http://127.0.0.1:8000 by default. If the uvicorn command is not found, use the Python module form instead: macOS / Linux python -m uvicorn runtime.api.server:app --reload Windows (PowerShell / Command Prompt) py -m uvicorn runtime.api.server:app --reload Tip: To allow access from other devices on your local network, bind to all interfaces: uvicorn runtime.api.server:app --host 0.0.0.0 --port 8000 --reload You can verify the server is up by opening: http://127.0.0.1:8000/agent/healthz You should see: { \"status\": \"ok\" }","title":"1. Start the runtime server"},{"location":"runtime_server_client/#2-using-an-android-emulator","text":"To run the example app (or your own APK) in an Android emulator and connect it to the AVA\u2011Gen runtime server, you will typically: Start the emulator. Install the AVA\u2011Gen client APK ( ava-gen-client.apk ). Install your example/app-under-test APK. Configure the client app to talk to the host machine ( 10.0.2.2:8000 ).","title":"2. Using an Android emulator"},{"location":"runtime_server_client/#21-start-an-emulator","text":"Use Android Studio\u2019s AVD Manager or the command line: Open Android Studio \u2192 Device Manager \u2192 create / start a virtual device. Or run: emulator -avd <your_avd_name>","title":"2.1 Start an emulator"},{"location":"runtime_server_client/#22-install-the-avagen-client-apk","text":"Once the emulator is running, install the provided AVA\u2011Gen client APK: adb install client/ava-gen-client_v1.apk On first launch, make sure: The app has Microphone permission (Search Permissions \u2192 Microphone and enable it). If your test device/emulator groups these permissions under Accessibility, ensure the microphone permission is enabled there as well.","title":"2.2 Install the AVA\u2011Gen client APK"},{"location":"runtime_server_client/#23-install-your-exampleapp-under-test-apk","text":"Once the emulator is running, install your example APK via adb : adb install path/to/your_app.apk If you rebuilt the APK, you may need: adb install -r path/to/your_app.apk For the running example of hu.vmiklos.plees_tracker , please: adb install examples/plees-tracker-24.8.1.apk You should see AVA-Gen app in the Accessibility Tool List after the installation.","title":"2.3 Install your example/app-under-test APK"},{"location":"runtime_server_client/#24-configure-the-client-app-to-talk-to-the-server","text":"Inside an Android emulator: 10.0.2.2 is a special alias that points to your host\u2019s 127.0.0.1 . So as long as you run the server and the emulator (with client) on the same computer (MacOS or Windows), you should see everything connect together automatically.","title":"2.4 Configure the client app to talk to the server"},{"location":"runtime_server_client/#3-using-a-real-android-device-phone","text":"You can also connect a physical phone to the AVA\u2011Gen runtime running on your Mac or Windows machine. There are two common patterns: Use adb reverse (USB cable, no Wi\u2011Fi configuration). Put both phone and host on the same Wi\u2011Fi network (Not tested)","title":"3. Using a real Android device (phone)"},{"location":"runtime_server_client/#31-using-adb-reverse-recommended-for-development","text":"This works on Android 5.0+ and does not require exposing your server on the LAN. Enable USB debugging on your phone (Developer options). Connect the phone via USB. Verify the device is recognized: adb devices Start the AVA\u2011Gen server on your host: uvicorn runtime.api.server:app --reload Run adb reverse so the device can reach the host\u2019s port 8000 via its own localhost : adb reverse tcp:8000 tcp:8000 When the app calls, traffic is forwarded over USB to the AVA\u2011Gen server running on your Mac or Windows machine. On some cases, firewalls can block incoming connections. If the app cannot reach the server, check your firewall settings on macOS (System Settings \u2192 Network/Firewall) or Windows (Windows Defender Firewall).","title":"3.1 Using adb reverse (recommended for development)"},{"location":"runtime_server_client/#4-test-the-http-api-from-your-desktop-curl-postman","text":"Once the server is running, you can exercise the /agent API directly from your Mac or Windows machine. This is useful for debugging before wiring up the Android client. The runtime exposes three key endpoints, all under the /agent prefix: GET /agent/healthz Simple health check. POST /agent/start_session Returns a new session_id you use for subsequent requests. POST /agent/request Main interaction endpoint; takes user messages plus session_id and app_id , and returns an AgentResponse (clarifying questions or an ActionPlan).","title":"4. Test the HTTP API from your desktop (curl / Postman)"},{"location":"runtime_server_client/#41-start-a-session-curl","text":"curl -X POST http://127.0.0.1:8000/agent/start_session Example response: { \"session_id\": \"abc123-session-id\" }","title":"4.1 Start a session (curl)"},{"location":"runtime_server_client/#42-send-a-request-curl","text":"Use the session_id above and the app id you have processed (for example hu.vmiklos.plees_tracker ): curl -X POST http://127.0.0.1:8000/agent/request \\ -H \"Content-Type: application/json\" \\ -d '{ \"session_id\": \"abc123-session-id\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"message\": \"Delete all existing sleep records\" }' The response shape is defined in runtime/models/api_models.py and normally includes a high-level status and, when applicable, an ActionPlan derived from your workspace/actionplan/<app_id>_actionplan.json .","title":"4.2 Send a request (curl)"},{"location":"runtime_server_client/#43-use-postman-or-similar","text":"If you prefer a GUI client like Postman or Insomnia: Create a new POST request to http://127.0.0.1:8000/agent/start_session . Send the request and copy the session_id from the JSON response. Create another POST request to http://127.0.0.1:8000/agent/request . Set the body type to raw JSON and provide: { \"session_id\": \"abc123-session-id\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"message\": \"Delete all existing sleep records\" } Send the request and inspect the JSON response (clarifications, selected ActionPlan, etc.).","title":"4.3 Use Postman (or similar)"},{"location":"tool_paper/","text":"Tool Paper & Evaluation Artifacts \u00b6 This page summarizes the research tool paper associated with AVA\u2011Gen and points to the evaluation data and reports stored in this repository. Paper information \u00b6 Title AVA-Gen: An Automated Voice Assistant Generation Framework from GUI Test Cases Reusing Abstract Voice assistants (VAs) are increasingly used on mobile devices, yet integrating VA capabilities into existing applications remains labor-intensive and difficult to scale. We present AVA-Gen, an automated framework that generates voice-assistant functionality directly from an app\u2019s GUI test code. AVA-Gen first builds a static analysis pipeline to convert the test methods to VA-ready artifacts, such as VA methods, task intents, skill descriptions, and executable action plans. At runtime, AVA-Gen provides a server\u2013client architecture that validates user intents and executes the generated action plans on an Android device. Our evaluation shows that AVA-Gen successfully converts 19 out of 20 test methods to VA methods from five applications, and correctly handles 88 of 100 simulated user queries with different accuracy levels. Evaluation data \u00b6 All evaluation data used in the paper is stored under the eval_data/ directory in this repository. 1. Evaluation workspaces \u00b6 All the five tested application apks (install files) and their generated artifacts are in the : eval_data/eval_workspace/ actionplan/ intent/ skills_description/ com.faltenreich.diaguard/ com.flauschcode.broccoli/ com.futsch1.medtimer/ hu.vmiklos.plees_tracker/ org.totschnig.myexpenses/ eval_data/apks/ 2. Evaluation reports \u00b6 Path: eval_data/eval_report/ This folder is reserved for evaluation summaries, metrics, and any post\u2011processing scripts or CSVs used in the paper\u2019s analysis.","title":"Tool Paper & Evaluation"},{"location":"tool_paper/#tool-paper-evaluation-artifacts","text":"This page summarizes the research tool paper associated with AVA\u2011Gen and points to the evaluation data and reports stored in this repository.","title":"Tool Paper &amp; Evaluation Artifacts"},{"location":"tool_paper/#paper-information","text":"Title AVA-Gen: An Automated Voice Assistant Generation Framework from GUI Test Cases Reusing Abstract Voice assistants (VAs) are increasingly used on mobile devices, yet integrating VA capabilities into existing applications remains labor-intensive and difficult to scale. We present AVA-Gen, an automated framework that generates voice-assistant functionality directly from an app\u2019s GUI test code. AVA-Gen first builds a static analysis pipeline to convert the test methods to VA-ready artifacts, such as VA methods, task intents, skill descriptions, and executable action plans. At runtime, AVA-Gen provides a server\u2013client architecture that validates user intents and executes the generated action plans on an Android device. Our evaluation shows that AVA-Gen successfully converts 19 out of 20 test methods to VA methods from five applications, and correctly handles 88 of 100 simulated user queries with different accuracy levels.","title":"Paper information"},{"location":"tool_paper/#evaluation-data","text":"All evaluation data used in the paper is stored under the eval_data/ directory in this repository.","title":"Evaluation data"},{"location":"tool_paper/#1-evaluation-workspaces","text":"All the five tested application apks (install files) and their generated artifacts are in the : eval_data/eval_workspace/ actionplan/ intent/ skills_description/ com.faltenreich.diaguard/ com.flauschcode.broccoli/ com.futsch1.medtimer/ hu.vmiklos.plees_tracker/ org.totschnig.myexpenses/ eval_data/apks/","title":"1. Evaluation workspaces"},{"location":"tool_paper/#2-evaluation-reports","text":"Path: eval_data/eval_report/ This folder is reserved for evaluation summaries, metrics, and any post\u2011processing scripts or CSVs used in the paper\u2019s analysis.","title":"2. Evaluation reports"},{"location":"old/","text":"AVA-Gen \u00b6 Convert existing Espresso UI tests (Java/Kotlin) into VA skill code and human-friendly skill descriptions. This site documents the core pipeline and the CLI wrapper added in this repo. The converter works against a per-app workspace folder and, together with the interpreters, produces: extracted_tests/ \u2014 stripped individual @Test methods va_methods/ \u2014 generated VA Java methods (one per test) skills_description/<app_id>_skills_description.json \u2014 per-app skill descriptions (via GPT) intent/intent_list_full.json \u2014 aggregated intents (for GPT intent matching) intent/intent_method_map.json \u2014 intent \u2192 method_name mapping (for the runtime) actionplan/<app_id>_actionplan.json \u2014 per-app ActionPlans for the client Use the ava-gen CLI to run the pipeline end-to-end or jump into the core modules for direct integration.","title":"AVA-Gen"},{"location":"old/#ava-gen","text":"Convert existing Espresso UI tests (Java/Kotlin) into VA skill code and human-friendly skill descriptions. This site documents the core pipeline and the CLI wrapper added in this repo. The converter works against a per-app workspace folder and, together with the interpreters, produces: extracted_tests/ \u2014 stripped individual @Test methods va_methods/ \u2014 generated VA Java methods (one per test) skills_description/<app_id>_skills_description.json \u2014 per-app skill descriptions (via GPT) intent/intent_list_full.json \u2014 aggregated intents (for GPT intent matching) intent/intent_method_map.json \u2014 intent \u2192 method_name mapping (for the runtime) actionplan/<app_id>_actionplan.json \u2014 per-app ActionPlans for the client Use the ava-gen CLI to run the pipeline end-to-end or jump into the core modules for direct integration.","title":"AVA-Gen"},{"location":"old/core-modules/","text":"Core Modules \u00b6 Converter (core/converter/espresso) \u00b6 va_code_generator.py process_app_workspace(app_id, workspace_root=\"workspace\") : orchestrates input reading, test extraction, and VA method generation. generate_va_method_from_test_method(method_src, language) : removes @Test , strips Test suffix, rewrites Espresso statements to VA API, preserves allowed helper calls. split_test_methods_from_java_source / split_test_methods_from_kotlin_source : split classes into individual @Test blocks. statement_converter.py convert_espresso_statement(espresso_statement) : validates matchers/actions, normalizes IDs, flattens allOf , removes isDisplayed , maps Espresso actions to VA API calls. java_extractor.py / kotlin_extractor.py Extract Espresso onView(...).perform(...) statements per language to feed the converter. Interpreter (core/interpreter) \u00b6 skill_interpreter.py interpret(workspace_root=\"workspace\", app_id) : Loads optional app_introduction.txt . Reads all VA methods under va_methods/ . Asks GPT for short + detailed descriptions per method. Aggregates into { \"app_id\": ..., \"context_methods\": { method: { \"description-short\": ..., \"description-detail\": ... } } } . prompts.py Prompt templates for short/detailed intents and parameter extraction (parameters kept for compatibility but not emitted). models.py SkillSchema Pydantic model with description_short and description_detail (exported as description-short / description-detail in JSON). OpenAI Client (core/api/openai_client.py) \u00b6 Configuration is centralized in configs/settings.Settings : Reads OPENAI_API_KEY from env (fails fast if missing). Optional OPENAI_BASE_URL for custom / proxy endpoints. Default model name from AVA_GEN_OPENAI_MODEL or gpt-4.1-mini . send_request_to_gpt(prompt, structured_output=False, model=None) : thin wrapper around chat.completions.create with optional structured output via Pydantic models. Package Init \u00b6 __init__.py at the project root loads .env at import time to make env vars available globally when the package is imported.","title":"Core Modules"},{"location":"old/core-modules/#core-modules","text":"","title":"Core Modules"},{"location":"old/core-modules/#converter-coreconverterespresso","text":"va_code_generator.py process_app_workspace(app_id, workspace_root=\"workspace\") : orchestrates input reading, test extraction, and VA method generation. generate_va_method_from_test_method(method_src, language) : removes @Test , strips Test suffix, rewrites Espresso statements to VA API, preserves allowed helper calls. split_test_methods_from_java_source / split_test_methods_from_kotlin_source : split classes into individual @Test blocks. statement_converter.py convert_espresso_statement(espresso_statement) : validates matchers/actions, normalizes IDs, flattens allOf , removes isDisplayed , maps Espresso actions to VA API calls. java_extractor.py / kotlin_extractor.py Extract Espresso onView(...).perform(...) statements per language to feed the converter.","title":"Converter (core/converter/espresso)"},{"location":"old/core-modules/#interpreter-coreinterpreter","text":"skill_interpreter.py interpret(workspace_root=\"workspace\", app_id) : Loads optional app_introduction.txt . Reads all VA methods under va_methods/ . Asks GPT for short + detailed descriptions per method. Aggregates into { \"app_id\": ..., \"context_methods\": { method: { \"description-short\": ..., \"description-detail\": ... } } } . prompts.py Prompt templates for short/detailed intents and parameter extraction (parameters kept for compatibility but not emitted). models.py SkillSchema Pydantic model with description_short and description_detail (exported as description-short / description-detail in JSON).","title":"Interpreter (core/interpreter)"},{"location":"old/core-modules/#openai-client-coreapiopenai_clientpy","text":"Configuration is centralized in configs/settings.Settings : Reads OPENAI_API_KEY from env (fails fast if missing). Optional OPENAI_BASE_URL for custom / proxy endpoints. Default model name from AVA_GEN_OPENAI_MODEL or gpt-4.1-mini . send_request_to_gpt(prompt, structured_output=False, model=None) : thin wrapper around chat.completions.create with optional structured output via Pydantic models.","title":"OpenAI Client (core/api/openai_client.py)"},{"location":"old/core-modules/#package-init","text":"__init__.py at the project root loads .env at import time to make env vars available globally when the package is imported.","title":"Package Init"},{"location":"old/design_actionplan/","text":"Action Plan Client-Side Design \u00b6 This document captures the client-side data model for executing Action Plans generated by the Test2VA server. The goal: instead of hard-coded, per-app Java methods, the Android client executes a JSON-defined action plan composed of primitive UI actions (click, input, scroll, etc.) targeting nodes via NodeQuery . 1. Example Server JSON (per app) \u00b6 Example file: hu.vmiklos.plees_tracker_actionplan.json { \"app_id\": \"hu.vmiklos.plees_tracker\", \"action_plans\": { \"accessStatistics\": { \"method_name\": \"accessStatistics\", \"steps\": [ { \"action\": \"sleep\", \"matchers\": [], \"text\": null, \"millis\": 1000, \"node_query\": null }, { \"action\": \"click\", \"matchers\": [ { \"type\": \"contentDescription\", \"value\": \"More options\" } ], \"text\": null, \"millis\": null, \"node_query\": \"withContentDescription(\\\"More options\\\")\" } ] } } } Notes \"app_id\" identifies the target Android app. \"action_plans\" is a map: VA method name -> ActionPlan . Each ActionPlan contains a list of primitive steps . Each step has an action (sleep, click, etc.), optional matchers , text , millis , and an optional node_query string. 2. Top-Level Container: AppActionPlans \u00b6 Represents all action plans for a single app . Fields String appId maps from JSON \"app_id\" Map<String, ActionPlan> actionPlans maps from JSON \"action_plans\" key: VA method name, e.g. \"accessStatistics\" value: corresponding ActionPlan Purpose Loaded once when the client opens the per-app JSON file. Cached by appId so that subsequent requests for the same app do not re-parse JSON. Provides a lookup method like getPlanForMethod(String methodName) . 3. ActionPlan \u00b6 Represents one VA method\u2019s plan (e.g., accessStatistics ). Fields String methodName from JSON \"method_name\" List<ActionStep> steps from JSON \"steps\" Optional Extensions (Future) String description String planId long createdAt These are not in the current JSON, but the model can easily grow to include them if the server starts emitting additional metadata. Behavior boolean isEmpty() convenience helper. String toString() for logging. 4. ActionStep \u00b6 Represents a single primitive UI operation in a plan. Fields String action (raw) from JSON \"action\" (e.g., \"sleep\" , \"click\" , \"input_text\" ) mapped lazily to an enum ActionType for type safety. List<StepMatcher> matchers from JSON \"matchers\" String text (nullable) from JSON \"text\" (e.g., input text for INPUT_TEXT ) Long millis (nullable) from JSON \"millis\" (e.g., sleep time) String nodeQueryExpr (nullable) from JSON \"node_query\" text form of a NodeQuery , e.g. withContentDescription(\"More options\") Derived / Client-Only Fields NodeQuery nodeQuery (transient) constructed client-side by parsing nodeQueryExpr or synthesizing from matchers . ActionType actionType (transient) enum wrapper around action with logic like requiresNode() . Example Responsibilities ActionType getActionType() \u2192 maps raw string to enum. boolean requiresTargetNode() \u2192 delegate to ActionType.requiresNode() . 5. StepMatcher \u00b6 Represents one element in the \"matchers\" array. Fields String type from JSON \"type\" (e.g., \"contentDescription\" , \"text\" , \"id\" ) String value from JSON \"value\" Intended Mapping to NodeQuery type = \"contentDescription\" \u2192 withContentDescription(value) type = \"text\" \u2192 withText(value) type = \"id\" \u2192 withId(value) This allows two strategies for building NodeQuery on the client: Parse nodeQueryExpr string into a NodeQuery AST, or Ignore nodeQueryExpr and rebuild the NodeQuery from the list of StepMatcher objects. The design supports either or both approaches. 6. ActionType Enum \u00b6 Client-side enum for known action values. The raw strings must match what the server/action plan parser emits. Example members: SLEEP(\"sleep\", false) CLICK(\"click\", true) INPUT_TEXT(\"input_text\", true) SCROLL(\"scroll\", true) GLOBAL_BACK(\"global_back\", false) UNKNOWN(\"unknown\", false) Each enum value can carry: String raw \u2192 exact string used in JSON. boolean requiresNode \u2192 whether an AccessibilityNodeInfo target is mandatory. Helper: static ActionType fromRaw(String raw) \u2192 maps incoming JSON to enum. 7. How the Client Uses These Classes \u00b6 7.1 Loading Action Plans \u00b6 Read per-app JSON (e.g., from assets, local storage, or server cache). Deserialize to AppActionPlans (e.g., using Gson). Cache AppActionPlans by appId . String json = loadFromAssets(\"hu.vmiklos.plees_tracker_actionplan.json\"); AppActionPlans appPlans = AppActionPlans.fromJson(json); ActionPlan plan = appPlans.getPlanForMethod(\"accessStatistics\"); 7.2 Executing a VA Method via ActionPlan \u00b6 When the server asks the client to execute a VA method (e.g., \"accessStatistics\" ): Look up the corresponding plan: ActionPlan plan = appPlans.getPlanForMethod(\"accessStatistics\"); Hand it to the executor: actionPlanExecutor.executePlan(appId, plan); Inside ActionPlanExecutor : Loop over plan.getSteps() . For each ActionStep : Map action string to ActionType . Build/parse NodeQuery from nodeQueryExpr and/or matchers . Dispatch to ActionPerformer : performClick(node) performInput(node, text) performScroll(node, dir) sleep(millis) performBack() etc. 7.3 Relationship to Existing Client Pieces \u00b6 ActionPlanExecutor replaces the old reflection-based AppTaskExecutor . NodeQueryExecutor + ActionPerformer reuse your existing Accessibility logic. TaskRegistry no longer needs to know app-specific methods; at most, it can store per-app configuration (package name, entry activity, etc.). 8. Summary \u00b6 Server : produces per-app JSON files describing VA methods as ActionPlans . Client : uses AppActionPlans , ActionPlan , ActionStep , StepMatcher , and ActionType to: Parse the JSON. Map abstract steps to concrete NodeQuery operations. Execute them through Accessibility APIs. This design removes hard-coded, per-app VA methods on the client and replaces them with a generic, extensible execution engine driven entirely by server-generated Action Plans.","title":"Action Plan Client-Side Design"},{"location":"old/design_actionplan/#action-plan-client-side-design","text":"This document captures the client-side data model for executing Action Plans generated by the Test2VA server. The goal: instead of hard-coded, per-app Java methods, the Android client executes a JSON-defined action plan composed of primitive UI actions (click, input, scroll, etc.) targeting nodes via NodeQuery .","title":"Action Plan Client-Side Design"},{"location":"old/design_actionplan/#1-example-server-json-per-app","text":"Example file: hu.vmiklos.plees_tracker_actionplan.json { \"app_id\": \"hu.vmiklos.plees_tracker\", \"action_plans\": { \"accessStatistics\": { \"method_name\": \"accessStatistics\", \"steps\": [ { \"action\": \"sleep\", \"matchers\": [], \"text\": null, \"millis\": 1000, \"node_query\": null }, { \"action\": \"click\", \"matchers\": [ { \"type\": \"contentDescription\", \"value\": \"More options\" } ], \"text\": null, \"millis\": null, \"node_query\": \"withContentDescription(\\\"More options\\\")\" } ] } } } Notes \"app_id\" identifies the target Android app. \"action_plans\" is a map: VA method name -> ActionPlan . Each ActionPlan contains a list of primitive steps . Each step has an action (sleep, click, etc.), optional matchers , text , millis , and an optional node_query string.","title":"1. Example Server JSON (per app)"},{"location":"old/design_actionplan/#2-top-level-container-appactionplans","text":"Represents all action plans for a single app . Fields String appId maps from JSON \"app_id\" Map<String, ActionPlan> actionPlans maps from JSON \"action_plans\" key: VA method name, e.g. \"accessStatistics\" value: corresponding ActionPlan Purpose Loaded once when the client opens the per-app JSON file. Cached by appId so that subsequent requests for the same app do not re-parse JSON. Provides a lookup method like getPlanForMethod(String methodName) .","title":"2. Top-Level Container: AppActionPlans"},{"location":"old/design_actionplan/#3-actionplan","text":"Represents one VA method\u2019s plan (e.g., accessStatistics ). Fields String methodName from JSON \"method_name\" List<ActionStep> steps from JSON \"steps\" Optional Extensions (Future) String description String planId long createdAt These are not in the current JSON, but the model can easily grow to include them if the server starts emitting additional metadata. Behavior boolean isEmpty() convenience helper. String toString() for logging.","title":"3. ActionPlan"},{"location":"old/design_actionplan/#4-actionstep","text":"Represents a single primitive UI operation in a plan. Fields String action (raw) from JSON \"action\" (e.g., \"sleep\" , \"click\" , \"input_text\" ) mapped lazily to an enum ActionType for type safety. List<StepMatcher> matchers from JSON \"matchers\" String text (nullable) from JSON \"text\" (e.g., input text for INPUT_TEXT ) Long millis (nullable) from JSON \"millis\" (e.g., sleep time) String nodeQueryExpr (nullable) from JSON \"node_query\" text form of a NodeQuery , e.g. withContentDescription(\"More options\") Derived / Client-Only Fields NodeQuery nodeQuery (transient) constructed client-side by parsing nodeQueryExpr or synthesizing from matchers . ActionType actionType (transient) enum wrapper around action with logic like requiresNode() . Example Responsibilities ActionType getActionType() \u2192 maps raw string to enum. boolean requiresTargetNode() \u2192 delegate to ActionType.requiresNode() .","title":"4. ActionStep"},{"location":"old/design_actionplan/#5-stepmatcher","text":"Represents one element in the \"matchers\" array. Fields String type from JSON \"type\" (e.g., \"contentDescription\" , \"text\" , \"id\" ) String value from JSON \"value\" Intended Mapping to NodeQuery type = \"contentDescription\" \u2192 withContentDescription(value) type = \"text\" \u2192 withText(value) type = \"id\" \u2192 withId(value) This allows two strategies for building NodeQuery on the client: Parse nodeQueryExpr string into a NodeQuery AST, or Ignore nodeQueryExpr and rebuild the NodeQuery from the list of StepMatcher objects. The design supports either or both approaches.","title":"5. StepMatcher"},{"location":"old/design_actionplan/#6-actiontype-enum","text":"Client-side enum for known action values. The raw strings must match what the server/action plan parser emits. Example members: SLEEP(\"sleep\", false) CLICK(\"click\", true) INPUT_TEXT(\"input_text\", true) SCROLL(\"scroll\", true) GLOBAL_BACK(\"global_back\", false) UNKNOWN(\"unknown\", false) Each enum value can carry: String raw \u2192 exact string used in JSON. boolean requiresNode \u2192 whether an AccessibilityNodeInfo target is mandatory. Helper: static ActionType fromRaw(String raw) \u2192 maps incoming JSON to enum.","title":"6. ActionType Enum"},{"location":"old/design_actionplan/#7-how-the-client-uses-these-classes","text":"","title":"7. How the Client Uses These Classes"},{"location":"old/design_actionplan/#71-loading-action-plans","text":"Read per-app JSON (e.g., from assets, local storage, or server cache). Deserialize to AppActionPlans (e.g., using Gson). Cache AppActionPlans by appId . String json = loadFromAssets(\"hu.vmiklos.plees_tracker_actionplan.json\"); AppActionPlans appPlans = AppActionPlans.fromJson(json); ActionPlan plan = appPlans.getPlanForMethod(\"accessStatistics\");","title":"7.1 Loading Action Plans"},{"location":"old/design_actionplan/#72-executing-a-va-method-via-actionplan","text":"When the server asks the client to execute a VA method (e.g., \"accessStatistics\" ): Look up the corresponding plan: ActionPlan plan = appPlans.getPlanForMethod(\"accessStatistics\"); Hand it to the executor: actionPlanExecutor.executePlan(appId, plan); Inside ActionPlanExecutor : Loop over plan.getSteps() . For each ActionStep : Map action string to ActionType . Build/parse NodeQuery from nodeQueryExpr and/or matchers . Dispatch to ActionPerformer : performClick(node) performInput(node, text) performScroll(node, dir) sleep(millis) performBack() etc.","title":"7.2 Executing a VA Method via ActionPlan"},{"location":"old/design_actionplan/#73-relationship-to-existing-client-pieces","text":"ActionPlanExecutor replaces the old reflection-based AppTaskExecutor . NodeQueryExecutor + ActionPerformer reuse your existing Accessibility logic. TaskRegistry no longer needs to know app-specific methods; at most, it can store per-app configuration (package name, entry activity, etc.).","title":"7.3 Relationship to Existing Client Pieces"},{"location":"old/design_actionplan/#8-summary","text":"Server : produces per-app JSON files describing VA methods as ActionPlans . Client : uses AppActionPlans , ActionPlan , ActionStep , StepMatcher , and ActionType to: Parse the JSON. Map abstract steps to concrete NodeQuery operations. Execute them through Accessibility APIs. This design removes hard-coded, per-app VA methods on the client and replaces them with a generic, extensible execution engine driven entirely by server-generated Action Plans.","title":"8. Summary"},{"location":"old/getting-started/","text":"Getting Started with AVA-Gen \u00b6 This guide summarizes the minimum steps needed to get AVA-Gen running for local development. For more detail, see the other docs in this folder. 1. Install dependencies \u00b6 From the project root: pip install . This installs the ava-gen CLI and the runtime components. 2. Configure environment \u00b6 Copy the example configuration and edit it: cp .env.example .env Set at least: OPENAI_API_KEY \u2013 your OpenAI API key. (Optionally) AVA_GEN_OPENAI_MODEL , AVA_GEN_WORKSPACE_ROOT , AVA_GEN_RUNTIME_DATA_DIR . 3. Run the CLI \u00b6 See docs/cli.md for the full pipeline. A typical flow: ava-gen prepare <app_id> path/to/MyTests.java ava-gen pipeline <app_id> This populates your workspace with extracted tests, VA methods, skill descriptions, and intent artifacts. 4. Start the runtime server \u00b6 Once you have generated skills, intents, and action plans, you can start the runtime server: uvicorn runtime.api.server:app --reload The runtime API surface and conversation flow are described in docs/runtime_design.md and docs/intent_validation.md .","title":"Getting Started with AVA-Gen"},{"location":"old/getting-started/#getting-started-with-ava-gen","text":"This guide summarizes the minimum steps needed to get AVA-Gen running for local development. For more detail, see the other docs in this folder.","title":"Getting Started with AVA-Gen"},{"location":"old/getting-started/#1-install-dependencies","text":"From the project root: pip install . This installs the ava-gen CLI and the runtime components.","title":"1. Install dependencies"},{"location":"old/getting-started/#2-configure-environment","text":"Copy the example configuration and edit it: cp .env.example .env Set at least: OPENAI_API_KEY \u2013 your OpenAI API key. (Optionally) AVA_GEN_OPENAI_MODEL , AVA_GEN_WORKSPACE_ROOT , AVA_GEN_RUNTIME_DATA_DIR .","title":"2. Configure environment"},{"location":"old/getting-started/#3-run-the-cli","text":"See docs/cli.md for the full pipeline. A typical flow: ava-gen prepare <app_id> path/to/MyTests.java ava-gen pipeline <app_id> This populates your workspace with extracted tests, VA methods, skill descriptions, and intent artifacts.","title":"3. Run the CLI"},{"location":"old/getting-started/#4-start-the-runtime-server","text":"Once you have generated skills, intents, and action plans, you can start the runtime server: uvicorn runtime.api.server:app --reload The runtime API surface and conversation flow are described in docs/runtime_design.md and docs/intent_validation.md .","title":"4. Start the runtime server"},{"location":"old/intent_validation/","text":"Intent Validation Design (AVA-Gen) \u00b6 This document explains how intent validation works in the AVA-Gen runtime: how we decide whether a user\u2019s request is supported for a given app, how we map it to a VA method, and how that drives ActionPlan selection. 1. Goals \u00b6 Intent validation in AVA-Gen should: Constrain user requests to what each app actually supports. Reuse the skills descriptions you already generate (per-method). Support multi-turn conversations while still blocking topic shifts. Be backend-agnostic (OpenAI now, other models later). Return structured results so the runtime can clearly branch: unsupported \u2192 clarification supported but ambiguous \u2192 clarification supported + concrete method \u2192 action plan 2. Data Sources: skills \u2192 intents + intent\u2192method map \u00b6 For each app, we start from a skills description file under workspace/ : workspace/ skills_description/ {app_id}_skills_description.json Typical format (context_methods variant): { \"app_id\": \"hu.vmiklos.plees_tracker\", \"context_methods\": { \"accessStatistics\": { \"description-short\": \"Open sleep statistics view\", \"description-detail\": \"Opens the app's statistics screen to view summarized sleep data and averages.\" } } } From this, IntentInterpreter derives two runtime artifacts under workspace/intent/ : Intent list \u2013 for GPT only [ { \"app_id\": \"hu.vmiklos.plees_tracker\", \"intents\": [ \"Open sleep statistics view\", \"Opens the app's statistics screen to view summarized sleep data and averages.\" ], \"intent_summary\": \"Summarizes the main capabilities of the app in one short sentence.\" } ] Stored at: workspace/intent/intent_list_full.json Intent \u2192 method map \u2013 for server only { \"hu.vmiklos.plees_tracker\": { \"Open sleep statistics view\": \"accessStatistics\", \"Opens the app's statistics screen to view summarized sleep data and averages.\": \"accessStatistics\" } } Stored at: workspace/intent/intent_method_map.json Key separation: GPT sees only intent_list_full.json (strings). The runtime uses intent_method_map.json to resolve matched_intent \u2192 method_name . 3. Core Component: IntentValidator \u00b6 File: interpreter/intent_validator.py 3.1 Responsibilities \u00b6 Load all *_skills_description.json files from workspace/ . For each app_id , build: intents: List[str] \u2013 allowed intent descriptions. intent_to_method: Dict[str, str] \u2013 mapping intent \u2192 method_name (when available). Provide a runtime API to: Expose allowed intents for each app. Validate a user message against those intents using a pluggable backend. 3.2 Public API \u00b6 class IntentValidator: def get_intents_for_app(self, app_id: str) -> List[str]: ... def get_method_for_intent(self, app_id: str, intent: str) -> Optional[str]: ... def validate(self, app_id: str, message: str, history: Optional[List[Any]]) -> IntentValidationResult: ... IntentValidationResult \u00b6 @dataclass class IntentValidationResult: is_supported: bool matched_intent: Optional[str] = None method_name: Optional[str] = None # always resolved server-side from intent\u2192method map reason: Optional[str] = None 4. Backend Interface: IntentMatcherBackend \u00b6 To keep the system flexible, the actual \u201cAI\u201d piece is abstracted as a backend: class IntentMatcherBackend(Protocol): def match_intent( self, app_id: str, message: str, intents: List[str], history: Optional[List[Any]] = None, ) -> IntentValidationResult: ... Key design choices: The backend must only choose among the given intents , or reject. It cannot invent new intents or switch apps. It may look at a small history snippet (last few turns) to resolve pronouns, but cannot expand scope beyond the provided intents . 4.1 OpenAI Backend (intent-only schema) \u00b6 OpenAIIntentMatcherBackend implements IntentMatcherBackend using the project-local openai_client.send_request_to_gpt . Schema used for GPT responses: class IntentMatchResultModel(BaseModel): is_supported: bool matched_intent: Optional[str] = None reason: Optional[str] = None Key points: GPT never returns a method_name . matched_intent must be exactly one of the provided intent strings (or null ). reason is a short explanation (at most ~20 words) used for clarifications. send_request_to_gpt requests this schema and parses the model output as JSON (with some robustness against fenced ```json blocks). 5. Conversation Flow Integration \u00b6 File: runtime/agents/conversation_agent.py ConversationAgent is the \u201cbrain\u201d that uses IntentValidator and ActionPlanStore . 5.1 High-level flow \u00b6 On each /agent/request : Load Session from SessionStore . Append a user turn : Turn(role=\"user\", message=message, type=\"user\", timestamp=...) If intent_validator configured: response = self._handle_with_intent_validator(session, message) Otherwise: response = self._fallback_clarification(session, message) Save the updated session. Return AgentResponse to the caller (clarification or action_plan). 6. Intent Validation Logic in ConversationAgent \u00b6 6.1 _handle_with_intent_validator(...) \u00b6 Steps: Call the validator: result = intent_validator.validate( app_id=session.app_id, message=message, history=list(session.turns), ) Extract: is_supported = result.is_supported matched_intent = result.matched_intent reason = result.reason Case 1 \u2013 Not supported ( is_supported == False ) Build a clarification message explaining that the request is not supported for this app (using reason if available). Append a server turn with type=\"clarification_unsupported\" . Keep session.status = OPEN . Log event: intent_not_supported . Return: AgentResponse(type=\"clarification\", ...) Case 2 \u2013 Supported: resolve method via map Always resolve method_name from the server-side map, never from GPT: method_name: Optional[str] = None if result.matched_intent: method_name = intent_validator.get_method_for_intent( app_id=app_id, intent=result.matched_intent, ) If we cannot resolve method_name : Build a configuration clarification : \u201cI recognized your intent, but I could not map it to a concrete action. Please double-check the intent\u2192method configuration.\u201d Append server turn with type=\"clarification_ambiguous\" . Log event: intent_ambiguous . Return AgentResponse(type=\"clarification\", ...) . Case 3 \u2013 Have method_name : load ActionPlan Attempt: plan = actionplan_store.get_actionplan(app_id, method_name) If plan is missing: Build a no-plan clarification message. Append type=\"clarification_no_plan\" . Log event: actionplan_missing . Return AgentResponse(type=\"clarification\", ...) . Case 4 \u2013 Success: ActionPlan available We now have a valid ActionPlan and method. Construct a user-facing summary : If matched_intent is available, use it as the short message: server_message = matched_intent Otherwise fall back to: server_message = f\"Executing method '{method_name}' for app '{app_id}'.\" Append server turn with type=\"action_plan\" . Set session.status = ACTION_SENT . Log event: actionplan_selected . Return: AgentResponse( type=\"action_plan\", message=server_message, method_name=method_name, action_plan=plan, next_session_id=None, ) 7. Preventing Topic Shifts \u00b6 Key rules that prevent the user from drifting away from the app\u2019s domain: Fixed app_id per session Every session is tied to exactly one app_id . All validation uses that app\u2019s intents . Closed intent set IntentValidator.validate always passes a fixed list of intents for this app. The backend must only choose among these or say \u201cnot supported\u201d. Per-turn validation Every new user message in the session is validated again. If the user suddenly asks \u201cbook me a flight\u201d, that won\u2019t match any plees_tracker intents \u2192 is_supported=False \u2192 clarification. History is limited Only a small snippet of recent turns is provided to the backend. History is used for disambiguation , not for expanding to new capabilities or apps. 8. Session Lifecycle & Intent \u00b6 SessionStatus.OPEN No action plan has been sent yet. User can go through multiple rounds of clarification. SessionStatus.ACTION_SENT An ActionPlan has been chosen and returned to the client. The current session is \u201cconsumed\u201d for that VA request. Client can start a new session for the next task. 9. Summary \u00b6 skills_description \u2192 intent strings + intent\u2192method mapping . IntentValidator \u2192 central interface for: listing allowed intents per app validating messages with a backend IntentMatcherBackend \u2192 pluggable model layer (OpenAI or others). ConversationAgent \u2192 uses validation to: enforce app scope handle unsupported / ambiguous cases with clarifications produce ActionPlans when intent is solid. This gives you: Clear control over what each app supports. A clean separation between: data (skills + actionplans), inference (intent backend), runtime logic (ConversationAgent).","title":"Intent Validation Design (AVA-Gen)"},{"location":"old/intent_validation/#intent-validation-design-ava-gen","text":"This document explains how intent validation works in the AVA-Gen runtime: how we decide whether a user\u2019s request is supported for a given app, how we map it to a VA method, and how that drives ActionPlan selection.","title":"Intent Validation Design (AVA-Gen)"},{"location":"old/intent_validation/#1-goals","text":"Intent validation in AVA-Gen should: Constrain user requests to what each app actually supports. Reuse the skills descriptions you already generate (per-method). Support multi-turn conversations while still blocking topic shifts. Be backend-agnostic (OpenAI now, other models later). Return structured results so the runtime can clearly branch: unsupported \u2192 clarification supported but ambiguous \u2192 clarification supported + concrete method \u2192 action plan","title":"1. Goals"},{"location":"old/intent_validation/#2-data-sources-skills-intents-intentmethod-map","text":"For each app, we start from a skills description file under workspace/ : workspace/ skills_description/ {app_id}_skills_description.json Typical format (context_methods variant): { \"app_id\": \"hu.vmiklos.plees_tracker\", \"context_methods\": { \"accessStatistics\": { \"description-short\": \"Open sleep statistics view\", \"description-detail\": \"Opens the app's statistics screen to view summarized sleep data and averages.\" } } } From this, IntentInterpreter derives two runtime artifacts under workspace/intent/ : Intent list \u2013 for GPT only [ { \"app_id\": \"hu.vmiklos.plees_tracker\", \"intents\": [ \"Open sleep statistics view\", \"Opens the app's statistics screen to view summarized sleep data and averages.\" ], \"intent_summary\": \"Summarizes the main capabilities of the app in one short sentence.\" } ] Stored at: workspace/intent/intent_list_full.json Intent \u2192 method map \u2013 for server only { \"hu.vmiklos.plees_tracker\": { \"Open sleep statistics view\": \"accessStatistics\", \"Opens the app's statistics screen to view summarized sleep data and averages.\": \"accessStatistics\" } } Stored at: workspace/intent/intent_method_map.json Key separation: GPT sees only intent_list_full.json (strings). The runtime uses intent_method_map.json to resolve matched_intent \u2192 method_name .","title":"2. Data Sources: skills \u2192 intents + intent\u2192method map"},{"location":"old/intent_validation/#3-core-component-intentvalidator","text":"File: interpreter/intent_validator.py","title":"3. Core Component: IntentValidator"},{"location":"old/intent_validation/#31-responsibilities","text":"Load all *_skills_description.json files from workspace/ . For each app_id , build: intents: List[str] \u2013 allowed intent descriptions. intent_to_method: Dict[str, str] \u2013 mapping intent \u2192 method_name (when available). Provide a runtime API to: Expose allowed intents for each app. Validate a user message against those intents using a pluggable backend.","title":"3.1 Responsibilities"},{"location":"old/intent_validation/#32-public-api","text":"class IntentValidator: def get_intents_for_app(self, app_id: str) -> List[str]: ... def get_method_for_intent(self, app_id: str, intent: str) -> Optional[str]: ... def validate(self, app_id: str, message: str, history: Optional[List[Any]]) -> IntentValidationResult: ...","title":"3.2 Public API"},{"location":"old/intent_validation/#intentvalidationresult","text":"@dataclass class IntentValidationResult: is_supported: bool matched_intent: Optional[str] = None method_name: Optional[str] = None # always resolved server-side from intent\u2192method map reason: Optional[str] = None","title":"IntentValidationResult"},{"location":"old/intent_validation/#4-backend-interface-intentmatcherbackend","text":"To keep the system flexible, the actual \u201cAI\u201d piece is abstracted as a backend: class IntentMatcherBackend(Protocol): def match_intent( self, app_id: str, message: str, intents: List[str], history: Optional[List[Any]] = None, ) -> IntentValidationResult: ... Key design choices: The backend must only choose among the given intents , or reject. It cannot invent new intents or switch apps. It may look at a small history snippet (last few turns) to resolve pronouns, but cannot expand scope beyond the provided intents .","title":"4. Backend Interface: IntentMatcherBackend"},{"location":"old/intent_validation/#41-openai-backend-intent-only-schema","text":"OpenAIIntentMatcherBackend implements IntentMatcherBackend using the project-local openai_client.send_request_to_gpt . Schema used for GPT responses: class IntentMatchResultModel(BaseModel): is_supported: bool matched_intent: Optional[str] = None reason: Optional[str] = None Key points: GPT never returns a method_name . matched_intent must be exactly one of the provided intent strings (or null ). reason is a short explanation (at most ~20 words) used for clarifications. send_request_to_gpt requests this schema and parses the model output as JSON (with some robustness against fenced ```json blocks).","title":"4.1 OpenAI Backend (intent-only schema)"},{"location":"old/intent_validation/#5-conversation-flow-integration","text":"File: runtime/agents/conversation_agent.py ConversationAgent is the \u201cbrain\u201d that uses IntentValidator and ActionPlanStore .","title":"5. Conversation Flow Integration"},{"location":"old/intent_validation/#51-high-level-flow","text":"On each /agent/request : Load Session from SessionStore . Append a user turn : Turn(role=\"user\", message=message, type=\"user\", timestamp=...) If intent_validator configured: response = self._handle_with_intent_validator(session, message) Otherwise: response = self._fallback_clarification(session, message) Save the updated session. Return AgentResponse to the caller (clarification or action_plan).","title":"5.1 High-level flow"},{"location":"old/intent_validation/#6-intent-validation-logic-in-conversationagent","text":"","title":"6. Intent Validation Logic in ConversationAgent"},{"location":"old/intent_validation/#61-_handle_with_intent_validator","text":"Steps: Call the validator: result = intent_validator.validate( app_id=session.app_id, message=message, history=list(session.turns), ) Extract: is_supported = result.is_supported matched_intent = result.matched_intent reason = result.reason Case 1 \u2013 Not supported ( is_supported == False ) Build a clarification message explaining that the request is not supported for this app (using reason if available). Append a server turn with type=\"clarification_unsupported\" . Keep session.status = OPEN . Log event: intent_not_supported . Return: AgentResponse(type=\"clarification\", ...) Case 2 \u2013 Supported: resolve method via map Always resolve method_name from the server-side map, never from GPT: method_name: Optional[str] = None if result.matched_intent: method_name = intent_validator.get_method_for_intent( app_id=app_id, intent=result.matched_intent, ) If we cannot resolve method_name : Build a configuration clarification : \u201cI recognized your intent, but I could not map it to a concrete action. Please double-check the intent\u2192method configuration.\u201d Append server turn with type=\"clarification_ambiguous\" . Log event: intent_ambiguous . Return AgentResponse(type=\"clarification\", ...) . Case 3 \u2013 Have method_name : load ActionPlan Attempt: plan = actionplan_store.get_actionplan(app_id, method_name) If plan is missing: Build a no-plan clarification message. Append type=\"clarification_no_plan\" . Log event: actionplan_missing . Return AgentResponse(type=\"clarification\", ...) . Case 4 \u2013 Success: ActionPlan available We now have a valid ActionPlan and method. Construct a user-facing summary : If matched_intent is available, use it as the short message: server_message = matched_intent Otherwise fall back to: server_message = f\"Executing method '{method_name}' for app '{app_id}'.\" Append server turn with type=\"action_plan\" . Set session.status = ACTION_SENT . Log event: actionplan_selected . Return: AgentResponse( type=\"action_plan\", message=server_message, method_name=method_name, action_plan=plan, next_session_id=None, )","title":"6.1 _handle_with_intent_validator(...)"},{"location":"old/intent_validation/#7-preventing-topic-shifts","text":"Key rules that prevent the user from drifting away from the app\u2019s domain: Fixed app_id per session Every session is tied to exactly one app_id . All validation uses that app\u2019s intents . Closed intent set IntentValidator.validate always passes a fixed list of intents for this app. The backend must only choose among these or say \u201cnot supported\u201d. Per-turn validation Every new user message in the session is validated again. If the user suddenly asks \u201cbook me a flight\u201d, that won\u2019t match any plees_tracker intents \u2192 is_supported=False \u2192 clarification. History is limited Only a small snippet of recent turns is provided to the backend. History is used for disambiguation , not for expanding to new capabilities or apps.","title":"7. Preventing Topic Shifts"},{"location":"old/intent_validation/#8-session-lifecycle-intent","text":"SessionStatus.OPEN No action plan has been sent yet. User can go through multiple rounds of clarification. SessionStatus.ACTION_SENT An ActionPlan has been chosen and returned to the client. The current session is \u201cconsumed\u201d for that VA request. Client can start a new session for the next task.","title":"8. Session Lifecycle &amp; Intent"},{"location":"old/intent_validation/#9-summary","text":"skills_description \u2192 intent strings + intent\u2192method mapping . IntentValidator \u2192 central interface for: listing allowed intents per app validating messages with a backend IntentMatcherBackend \u2192 pluggable model layer (OpenAI or others). ConversationAgent \u2192 uses validation to: enforce app scope handle unsupported / ambiguous cases with clarifications produce ActionPlans when intent is solid. This gives you: Clear control over what each app supports. A clean separation between: data (skills + actionplans), inference (intent backend), runtime logic (ConversationAgent).","title":"9. Summary"},{"location":"old/pipeline/","text":"Pipeline \u00b6 Workspace Layout (per app) \u00b6 workspace/ <app_id>/ input/ app_introduction.txt # optional app-level context for GPT *.java # Espresso test classes *.kt # Espresso test classes (Kotlin) extracted_tests/ # GENERATED: one @Test method per file va_methods/ # GENERATED: VA Java methods (one per test) skills_description/ <app_id>_skills_description.json # GENERATED: per-app skill descriptions intent/ intent_list_full.json # GENERATED: per-app intents (plus optional intent_summary) intent_method_map.json # GENERATED: intent -> method_name mapping actionplan/ <app_id>_actionplan.json # GENERATED: per-app ActionPlans Developer responsibility: place test classes (and optional intro) into workspace/<app_id>/input/ before running. End-to-End Flow \u00b6 Parse & split tests process_app_workspace() (core/converter/espresso/va_code_generator.py) iterates over input/ , skipping app_introduction.txt , and splits each Java/Kotlin class into individual @Test methods ( extracted_tests/ ). Generate VA methods Each test method is converted to a VA Java method via generate_va_method_from_test_method() , which: Removes @Test , strips Test suffix from the method name. Extracts Espresso statements and rewrites them into the VA API (performClick, performInput, performSwipe*, etc.). Keeps a subset of non-Espresso helpers (pressBack, closeSoftKeyboard, Thread.sleep) while filtering assertions. Output is saved in va_methods/ with Test suffix removed. Interpret skills skill_interpreter.interpret_all_methods(app_id, workspace_root) reads all VA methods under va_methods/ , loads optional app_introduction.txt , asks GPT for short and detailed descriptions per method, and aggregates: { \"app_id\": \"<app_id>\", \"context_methods\": { \"<methodName>\": { \"description-short\": \"<short intent>\", \"description-detail\": \"<detailed intent>\" } } } The CLI writes this to: workspace/skills_description/<app_id>_skills_description.json Build intents IntentInterpreter.export_full_intent_list() and IntentInterpreter.export_intent_method_map() aggregate all per-app skill descriptions into: workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json These files are used by the runtime for intent validation. Build ActionPlans generate_action_plans_for_app(app_id, workspace_root) parses each VA method into an ActionPlan and writes: workspace/actionplan/<app_id>_actionplan.json Runtime The FastAPI runtime ( runtime/api/server.py ) loads the generated skills_description , intent , and actionplan artifacts to power conversational intent validation and ActionPlan selection. See docs/runtime_design.md and docs/intent_validation.md for details. Statement Conversion Highlights \u00b6 File: core/converter/espresso/statement_converter.py Validates matchers/actions against supported allowlists. Normalizes withId(R.id.foo) \u2192 withId(\"foo\") ; also handles android.R.id . Flattens allOf(...) , drops isDisplayed() . Rewrites onView(...) \u2192 findNode(...) . Maps actions: .perform(click()) \u2192 performClick(findNode(...)); .perform(typeText/replaceText(val)) \u2192 performInput(findNode(...), val); .perform(swipeLeft/Right()) \u2192 performSwipeLeft|RightOnNode(findNode(...)); onView(isRoot()).perform(swipeLeft()) \u2192 performSwipeLeft(); (root-level)","title":"Pipeline"},{"location":"old/pipeline/#pipeline","text":"","title":"Pipeline"},{"location":"old/pipeline/#workspace-layout-per-app","text":"workspace/ <app_id>/ input/ app_introduction.txt # optional app-level context for GPT *.java # Espresso test classes *.kt # Espresso test classes (Kotlin) extracted_tests/ # GENERATED: one @Test method per file va_methods/ # GENERATED: VA Java methods (one per test) skills_description/ <app_id>_skills_description.json # GENERATED: per-app skill descriptions intent/ intent_list_full.json # GENERATED: per-app intents (plus optional intent_summary) intent_method_map.json # GENERATED: intent -> method_name mapping actionplan/ <app_id>_actionplan.json # GENERATED: per-app ActionPlans Developer responsibility: place test classes (and optional intro) into workspace/<app_id>/input/ before running.","title":"Workspace Layout (per app)"},{"location":"old/pipeline/#end-to-end-flow","text":"Parse & split tests process_app_workspace() (core/converter/espresso/va_code_generator.py) iterates over input/ , skipping app_introduction.txt , and splits each Java/Kotlin class into individual @Test methods ( extracted_tests/ ). Generate VA methods Each test method is converted to a VA Java method via generate_va_method_from_test_method() , which: Removes @Test , strips Test suffix from the method name. Extracts Espresso statements and rewrites them into the VA API (performClick, performInput, performSwipe*, etc.). Keeps a subset of non-Espresso helpers (pressBack, closeSoftKeyboard, Thread.sleep) while filtering assertions. Output is saved in va_methods/ with Test suffix removed. Interpret skills skill_interpreter.interpret_all_methods(app_id, workspace_root) reads all VA methods under va_methods/ , loads optional app_introduction.txt , asks GPT for short and detailed descriptions per method, and aggregates: { \"app_id\": \"<app_id>\", \"context_methods\": { \"<methodName>\": { \"description-short\": \"<short intent>\", \"description-detail\": \"<detailed intent>\" } } } The CLI writes this to: workspace/skills_description/<app_id>_skills_description.json Build intents IntentInterpreter.export_full_intent_list() and IntentInterpreter.export_intent_method_map() aggregate all per-app skill descriptions into: workspace/intent/intent_list_full.json workspace/intent/intent_method_map.json These files are used by the runtime for intent validation. Build ActionPlans generate_action_plans_for_app(app_id, workspace_root) parses each VA method into an ActionPlan and writes: workspace/actionplan/<app_id>_actionplan.json Runtime The FastAPI runtime ( runtime/api/server.py ) loads the generated skills_description , intent , and actionplan artifacts to power conversational intent validation and ActionPlan selection. See docs/runtime_design.md and docs/intent_validation.md for details.","title":"End-to-End Flow"},{"location":"old/pipeline/#statement-conversion-highlights","text":"File: core/converter/espresso/statement_converter.py Validates matchers/actions against supported allowlists. Normalizes withId(R.id.foo) \u2192 withId(\"foo\") ; also handles android.R.id . Flattens allOf(...) , drops isDisplayed() . Rewrites onView(...) \u2192 findNode(...) . Maps actions: .perform(click()) \u2192 performClick(findNode(...)); .perform(typeText/replaceText(val)) \u2192 performInput(findNode(...), val); .perform(swipeLeft/Right()) \u2192 performSwipeLeft|RightOnNode(findNode(...)); onView(isRoot()).perform(swipeLeft()) \u2192 performSwipeLeft(); (root-level)","title":"Statement Conversion Highlights"},{"location":"old/runtime_design/","text":"AVA-Gen Runtime Design \u00b6 This document describes the runtime architecture of the AVA-gen local server. It is designed for a lightweight, local environment where the desktop/laptop (running AVA-gen) communicates with an Android device (via cable or Wi-Fi). The runtime supports: minimal sessions chat-style interaction conversation-driven ActionPlan retrieval simple file-based storage optional logging 1. Runtime Folder Structure \u00b6 runtime/ __init__.py api/ __init__.py server.py # FastAPI app + route mounting session_routes.py # /start_session, /agent/request agents/ __init__.py conversation_agent.py # core logic: history + decision to send AP or clarify store/ __init__.py session_store.py # in-memory + file-backed sessions actionplan_store.py # load workspace/<app_id>/*_actionplan.json log_store.py # append-only JSONL logs (optional) models/ __init__.py session_models.py # Session, Turn, SessionStatus enum api_models.py # Request/Response Pydantic models workspace/ <app_id>/ actionplan/ <app_id>_actionplan.json skills_description/ <app_id>_skills_description.json intent/ intent_list_full.json # per-app allowed intent strings (for GPT) intent_method_map.json # intent text -> method_name (for server) 2. Responsibilities of Each Component \u00b6 runtime/api/server.py \u00b6 Creates the FastAPI app Includes session-related routes from session_routes.py runtime/api/session_routes.py \u00b6 Endpoints: POST /start_session POST /agent/request Uses: SessionStore ConversationAgent ActionPlanStore runtime/agents/conversation_agent.py \u00b6 Given: Session (with history) New user message Decides: Append to history Use IntentValidator to check whether the message is supported for this app. If supported: resolve matched_intent into a concrete VA method_name via the server-side map. If method found: fetch ActionPlan and return it. Otherwise: return a clarification. Returns: AgentResponse(type=\"clarification\", ...) AgentResponse(type=\"action_plan\", ...) runtime/store/session_store.py \u00b6 Minimal session object: session_id: str app_id: str | null (bound on first /agent/request ) history: List[Turn] status: OPEN | ACTION_SENT | CLOSED In-memory dict: sessions: Dict[str, Session] Optional: write to runtime/data/sessions/<session_id>.json runtime/store/actionplan_store.py \u00b6 Loads action plans from: workspace/<app_id>/actionplan/<app_id>_actionplan.json Provides: get_actionplan(app_id, method_name) runtime/store/log_store.py \u00b6 Append JSONL entries to: runtime/data/logs/actions_YYYY-MM-DD.jsonl Format example: { \"ts\": \"2025-11-25T14:10:00Z\", \"session_id\": \"123\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"event_type\": \"action_plan_sent\", \"payload\": { \"method_name\": \"accessStatistics\", \"step_count\": 5 } } 3. Session Flow (Matches the 5 Rules) \u00b6 1\ufe0f\u20e3 Start Session \u00b6 Client: POST /start_session Server: creates session_id (uuid4) initializes history status = OPEN logs event Response: { \"session_id\": \"<uuid>\" } 2\ufe0f\u20e3 Conversation within the session \u00b6 Client: POST /agent/request { \"session_id\": \"<id>\", \"app_id\": \"<app>\", \"message\": \"Open statistics screen\" } Server: loads session appends user turn runs ConversationAgent Agent decides: Need clarification OR ready to output ActionPlan 3\ufe0f\u20e3 If ActionPlan ready \u2192 rotate session \u00b6 Agent selects VA method (e.g., \"accessStatistics\" ): Server loads ActionPlan Marks current session CLOSED Creates next_session_id Response: { \"type\": \"action_plan\", \"session_id\": \"<old>\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"method_name\": \"accessStatistics\", \"action_plan\": { ... }, \"next_session_id\": \"<new>\" } 4\ufe0f\u20e3 History cached \u00b6 Every request: read session.history append turn agent uses full dialog context Optional session persistence: runtime/data/sessions/<session_id>.json 5\ufe0f\u20e3 Logging \u00b6 Every important event logged via LogStore: session_created user_message clarification_sent action_plan_sent Saved to: runtime/data/logs/actions_<date>.jsonl Summary \u00b6 This runtime design: keeps sessions lightweight allows multi-turn clarification returns JSON-based ActionPlans supports offline/local operation uses simple file-based storage aligns with AVA-gen\u2019s ActionPlan format","title":"AVA-Gen Runtime Design"},{"location":"old/runtime_design/#ava-gen-runtime-design","text":"This document describes the runtime architecture of the AVA-gen local server. It is designed for a lightweight, local environment where the desktop/laptop (running AVA-gen) communicates with an Android device (via cable or Wi-Fi). The runtime supports: minimal sessions chat-style interaction conversation-driven ActionPlan retrieval simple file-based storage optional logging","title":"AVA-Gen Runtime Design"},{"location":"old/runtime_design/#1-runtime-folder-structure","text":"runtime/ __init__.py api/ __init__.py server.py # FastAPI app + route mounting session_routes.py # /start_session, /agent/request agents/ __init__.py conversation_agent.py # core logic: history + decision to send AP or clarify store/ __init__.py session_store.py # in-memory + file-backed sessions actionplan_store.py # load workspace/<app_id>/*_actionplan.json log_store.py # append-only JSONL logs (optional) models/ __init__.py session_models.py # Session, Turn, SessionStatus enum api_models.py # Request/Response Pydantic models workspace/ <app_id>/ actionplan/ <app_id>_actionplan.json skills_description/ <app_id>_skills_description.json intent/ intent_list_full.json # per-app allowed intent strings (for GPT) intent_method_map.json # intent text -> method_name (for server)","title":"1. Runtime Folder Structure"},{"location":"old/runtime_design/#2-responsibilities-of-each-component","text":"","title":"2. Responsibilities of Each Component"},{"location":"old/runtime_design/#runtimeapiserverpy","text":"Creates the FastAPI app Includes session-related routes from session_routes.py","title":"runtime/api/server.py"},{"location":"old/runtime_design/#runtimeapisession_routespy","text":"Endpoints: POST /start_session POST /agent/request Uses: SessionStore ConversationAgent ActionPlanStore","title":"runtime/api/session_routes.py"},{"location":"old/runtime_design/#runtimeagentsconversation_agentpy","text":"Given: Session (with history) New user message Decides: Append to history Use IntentValidator to check whether the message is supported for this app. If supported: resolve matched_intent into a concrete VA method_name via the server-side map. If method found: fetch ActionPlan and return it. Otherwise: return a clarification. Returns: AgentResponse(type=\"clarification\", ...) AgentResponse(type=\"action_plan\", ...)","title":"runtime/agents/conversation_agent.py"},{"location":"old/runtime_design/#runtimestoresession_storepy","text":"Minimal session object: session_id: str app_id: str | null (bound on first /agent/request ) history: List[Turn] status: OPEN | ACTION_SENT | CLOSED In-memory dict: sessions: Dict[str, Session] Optional: write to runtime/data/sessions/<session_id>.json","title":"runtime/store/session_store.py"},{"location":"old/runtime_design/#runtimestoreactionplan_storepy","text":"Loads action plans from: workspace/<app_id>/actionplan/<app_id>_actionplan.json Provides: get_actionplan(app_id, method_name)","title":"runtime/store/actionplan_store.py"},{"location":"old/runtime_design/#runtimestorelog_storepy","text":"Append JSONL entries to: runtime/data/logs/actions_YYYY-MM-DD.jsonl Format example: { \"ts\": \"2025-11-25T14:10:00Z\", \"session_id\": \"123\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"event_type\": \"action_plan_sent\", \"payload\": { \"method_name\": \"accessStatistics\", \"step_count\": 5 } }","title":"runtime/store/log_store.py"},{"location":"old/runtime_design/#3-session-flow-matches-the-5-rules","text":"","title":"3. Session Flow (Matches the 5 Rules)"},{"location":"old/runtime_design/#1-start-session","text":"Client: POST /start_session Server: creates session_id (uuid4) initializes history status = OPEN logs event Response: { \"session_id\": \"<uuid>\" }","title":"1\ufe0f\u20e3 Start Session"},{"location":"old/runtime_design/#2-conversation-within-the-session","text":"Client: POST /agent/request { \"session_id\": \"<id>\", \"app_id\": \"<app>\", \"message\": \"Open statistics screen\" } Server: loads session appends user turn runs ConversationAgent Agent decides: Need clarification OR ready to output ActionPlan","title":"2\ufe0f\u20e3 Conversation within the session"},{"location":"old/runtime_design/#3-if-actionplan-ready-rotate-session","text":"Agent selects VA method (e.g., \"accessStatistics\" ): Server loads ActionPlan Marks current session CLOSED Creates next_session_id Response: { \"type\": \"action_plan\", \"session_id\": \"<old>\", \"app_id\": \"hu.vmiklos.plees_tracker\", \"method_name\": \"accessStatistics\", \"action_plan\": { ... }, \"next_session_id\": \"<new>\" }","title":"3\ufe0f\u20e3 If ActionPlan ready \u2192 rotate session"},{"location":"old/runtime_design/#4-history-cached","text":"Every request: read session.history append turn agent uses full dialog context Optional session persistence: runtime/data/sessions/<session_id>.json","title":"4\ufe0f\u20e3 History cached"},{"location":"old/runtime_design/#5-logging","text":"Every important event logged via LogStore: session_created user_message clarification_sent action_plan_sent Saved to: runtime/data/logs/actions_<date>.jsonl","title":"5\ufe0f\u20e3 Logging"},{"location":"old/runtime_design/#summary","text":"This runtime design: keeps sessions lightweight allows multi-turn clarification returns JSON-based ActionPlans supports offline/local operation uses simple file-based storage aligns with AVA-gen\u2019s ActionPlan format","title":"Summary"}]}